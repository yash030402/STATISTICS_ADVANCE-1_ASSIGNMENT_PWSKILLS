{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1 Explain the properties of the F-distribution ?"
      ],
      "metadata": {
        "id": "P-3G0pHL22b_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS. **Properties of the F-Distribution**\n",
        "\n",
        "**Definition:** The F-distribution is a continuous probability distribution that arises frequently in the analysis of variance (ANOVA) and in the comparison of two variances. It's used to compare sample variances to determine if they come from populations with equal variances.\n",
        "\n",
        "**Key Properties:**\n",
        "1. Shape:\n",
        "\n",
        "- The F-distribution is positively skewed, meaning it has a longer right tail.\n",
        "\n",
        "- As the degrees of freedom increase, the distribution becomes more symmetric.\n",
        "\n",
        "2. Degrees of Freedom:\n",
        "\n",
        "- The F-distribution depends on two sets of degrees of freedom:\n",
        "ùëë\n",
        "1\n",
        " (numerator) and\n",
        "ùëë\n",
        "2\n",
        " (denominator).\n",
        "\n",
        "- ùëë\n",
        "1\n",
        " is associated with the variance estimate in the numerator, and\n",
        "ùëë\n",
        "2\n",
        " with the variance estimate in the denominator.\n",
        "\n",
        "3. Range:\n",
        "\n",
        "- The F-distribution is defined for values\n",
        "ùêπ\n",
        "‚â•\n",
        "0\n",
        ". It never takes negative values.\n",
        "\n",
        "4. Mean:\n",
        "\n",
        "- The mean of the F-distribution depends on the degrees of freedom and is given by\n",
        "ùëë\n",
        "2\n",
        "ùëë\n",
        "2\n",
        "‚àí\n",
        "2\n",
        " for\n",
        "ùëë\n",
        "2\n",
        ">\n",
        "2\n",
        ".\n",
        "\n",
        "5. Variance:\n",
        "\n",
        "- The variance of the F-distribution is given by\n",
        "2\n",
        "ùëë\n",
        "2\n",
        "2\n",
        "(\n",
        "ùëë\n",
        "1\n",
        "+\n",
        "ùëë\n",
        "2\n",
        "‚àí\n",
        "2\n",
        ")\n",
        "ùëë\n",
        "1\n",
        "(\n",
        "ùëë\n",
        "2\n",
        "‚àí\n",
        "2\n",
        ")\n",
        "2\n",
        "(\n",
        "ùëë\n",
        "2\n",
        "‚àí\n",
        "4\n",
        ")\n",
        " for\n",
        "ùëë\n",
        "2\n",
        ">\n",
        "4\n",
        ".\n",
        "\n",
        "6. Applications:\n",
        "\n",
        "- Used in ANOVA for testing the equality of three or more means.\n",
        "\n",
        "- Applied in regression analysis to test the overall significance of a\n",
        "  regression model.\n",
        "\n",
        "- Utilized in comparing variances between two datasets to determine if they are\n",
        "  significantly different.\n",
        "\n",
        "**Example Application:**\n",
        "\n",
        "In ANOVA, the F-distribution is used to determine if the means of different groups are significantly different. If the calculated F-value from the sample data exceeds the critical value from the F-distribution table, we reject the null hypothesis, indicating that at least one group mean is different from the others."
      ],
      "metadata": {
        "id": "-RW7bwjh3Dvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2  In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
      ],
      "metadata": {
        "id": "NuOxWc6DJGFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS.The F-distribution is used in several key statistical tests because of its properties related to the ratio of variances. Here are some of the primary types of tests where the F-distribution is commonly applied:\n",
        "\n",
        "1. Analysis of Variance (ANOVA)\n",
        "\n",
        "- Purpose: To compare the means of three or more groups to determine if at  \n",
        "  least one group mean is significantly different from the others.\n",
        "\n",
        "- Why F-distribution?: ANOVA uses the F-distribution to compare the variance\n",
        "  among group means to the variance within the groups. The F-statistic is calculated as the ratio of these variances. A large F-value suggests that the group means are not all equal, indicating a significant difference.\n",
        "\n",
        "2. Regression Analysis\n",
        "\n",
        "- Purpose: To assess the overall significance of a regression model.\n",
        "\n",
        "- Why F-distribution?: In multiple regression, the F-test evaluates whether the\n",
        "  explained variance by the model is significantly greater than the unexplained variance. The F-statistic is used to test the null hypothesis that all regression coefficients are equal to zero (i.e., the model has no explanatory power).\n",
        "\n",
        "3. Comparing Two Variances (F-test)\n",
        "\n",
        "- Purpose: To compare the variances of two independent samples to determine if\n",
        "  they are significantly different.\n",
        "\n",
        "- Why F-distribution?: The F-test uses the F-distribution to compare the ratio\n",
        "  of two sample variances. If the variances are equal, the ratio should be close to 1. A significant deviation from 1 indicates a difference in variances.\n",
        "\n",
        "4. Testing Equality of Multiple Regression Coefficients\n",
        "\n",
        "- Purpose: To test if a subset of regression coefficients in a multiple\n",
        "   regression model are equal.\n",
        "\n",
        "- Why F-distribution?: The F-test in this context evaluates whether the         restricted model (with coefficients set to be equal) fits the data significantly worse than the unrestricted model. The F-statistic helps determine if the simpler model is sufficient.\n",
        "\n",
        "5. MANOVA (Multivariate Analysis of Variance)\n",
        "\n",
        "- Purpose: To compare the means of multiple dependent variables across groups.\n",
        "\n",
        "- Why F-distribution?: Similar to ANOVA, but with multiple dependent variables.\n",
        "  The F-distribution helps assess whether the group means for multiple dependent variables are significantly different.\n",
        "\n",
        "  \n",
        "\n",
        "The F-distribution is appropriate for these tests because it deals with the ratio of variances, a critical component in comparing group means, regression models, and variances across different contexts. It's a versatile and powerful tool in statistical analysis."
      ],
      "metadata": {
        "id": "rG0CArdQJJHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3  What are the key assumptions required for conducting an F-test to compare the variances of two\n",
        "populations?"
      ],
      "metadata": {
        "id": "L6VqyACxKBiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS.When conducting an F-test to compare the variances of two populations, several key assumptions must be met to ensure the validity of the test results. These assumptions are crucial for the test's accuracy and reliability:\n",
        "\n",
        "**Key Assumptions for the F-test:**\n",
        "\n",
        "1. Normality:\n",
        "\n",
        "- The populations from which the samples are drawn should follow a normal\n",
        "  distribution. This assumption is critical as the F-test is sensitive to deviations from normality.\n",
        "\n",
        "2. Independence:\n",
        "\n",
        "- The samples must be independent of each other. This means that the data from\n",
        "  one sample does not influence the data from the other sample.\n",
        "\n",
        "3. Random Sampling:\n",
        "\n",
        "- Both samples should be randomly selected from their respective populations.   This helps ensure that the samples are representative of the populations.\n",
        "\n",
        "4. Interval or Ratio Scale:\n",
        "\n",
        "- The data should be measured on an interval or ratio scale, meaning the\n",
        "  differences between data points are meaningful and the data has a true zero point.\n",
        "\n",
        "5. Equal Variances within Groups:\n",
        "\n",
        "- The variances within each group should be roughly equal. This assumption is\n",
        "  less stringent but is important for ensuring the test's robustness.\n",
        "\n",
        "**Why These Assumptions Are Important:**\n",
        "\n",
        "- Normality: Ensures that the sampling distribution of the test statistic\n",
        "  follows the F-distribution.\n",
        "\n",
        "- Independence: Prevents bias and ensures that the samples do not influence  \n",
        "  each other.\n",
        "\n",
        "- Random Sampling: Helps generalize the results to the populations.\n",
        "\n",
        "- Interval or Ratio Scale: Ensures that the computations of variance are\n",
        "  meaningful.\n",
        "\n",
        "- Equal Variances within Groups: Ensures that the F-test is robust and valid\n",
        "  under the null hypothesis.\n",
        "\n",
        "**Example Scenario:**\n",
        "\n",
        "Imagine you are comparing the variances in test scores between two different teaching methods. You would need to ensure that:\n",
        "\n",
        "1. The test scores for each method are normally distributed.\n",
        "\n",
        "2. The scores from students using one method are independent of the scores from\n",
        "   students using the other method.\n",
        "\n",
        "3. The samples of students are randomly selected.\n",
        "\n",
        "4. The test scores are measured on an interval scale.\n",
        "\n",
        "5. The variances within each teaching method group are approximately equal."
      ],
      "metadata": {
        "id": "9WqXYpbGKEvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4  What is the purpose of ANOVA, and how does it differ from a t-test?"
      ],
      "metadata": {
        "id": "tchnjNBaLFhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS. **Purpose of ANOVA (Analysis of Variance)**\n",
        "\n",
        "ANOVA is used to determine if there are any statistically significant differences between the means of three or more independent groups. The primary goal is to test the null hypothesis that all group means are equal.\n",
        "\n",
        "**How ANOVA Works:**\n",
        "\n",
        "- Between-Group Variance: Measures how much the group means differ from the\n",
        "  overall mean.\n",
        "\n",
        "- Within-Group Variance: Measures how much the individual data points differ\n",
        "  from their respective group means.\n",
        "\n",
        "- F-Statistic: ANOVA calculates an F-statistic, which is the ratio of    \n",
        "  between-group variance to within-group variance. A higher F-value indicates a greater likelihood that at least one group mean is different.\n",
        "\n",
        "**Types of ANOVA:**\n",
        "\n",
        "1. One-Way ANOVA: Compares means across one independent variable with multiple\n",
        "   groups.\n",
        "\n",
        "2. Two-Way ANOVA: Compares means across two independent variables, which can\n",
        "   show interaction effects between the variables.\n",
        "\n",
        "**Purpose of a t-test**\n",
        "\n",
        "t-test is used to determine if there is a significant difference between the means of two groups. It‚Äôs simpler than ANOVA and is applicable when comparing only two means.\n",
        "\n",
        "**Types of t-tests:**\n",
        "\n",
        "1. Independent t-test: Compares means from two different groups (e.g.,  \n",
        "   treatment vs. control).\n",
        "\n",
        "2. Paired t-test: Compares means from the same group at different times (e.g.,\n",
        "   pre-test vs. post-test).\n",
        "\n",
        "**Key Differences Between ANOVA and t-test:**\n",
        "\n",
        "1. Number of Groups:\n",
        "\n",
        "- t-test: Used for comparing the means of two groups.\n",
        "\n",
        "- ANOVA: Used for comparing the means of three or more groups.\n",
        "\n",
        "2. Test Statistic:\n",
        "\n",
        "- t-test: Produces a t-statistic.\n",
        "\n",
        "- ANOVA: Produces an F-statistic.\n",
        "\n",
        "3. Hypotheses Tested:\n",
        "\n",
        "- t-test: Tests if there is a significant difference between the means of two\n",
        "  groups.\n",
        "\n",
        "- ANOVA: Tests if there is a significant difference among the means of three or more groups.\n",
        "\n",
        "4. Post-hoc Testing:\n",
        "\n",
        "- t-test: Typically doesn‚Äôt require post-hoc testing since it only compares two\n",
        "  groups.\n",
        "\n",
        "- ANOVA: If the F-test is significant, post-hoc tests (e.g., Tukey, Bonferroni)\n",
        "  are conducted to determine which specific groups are different.\n",
        "\n",
        "**Example Scenarios:**\n",
        "\n",
        "- t-test: Comparing average test scores of students from two different schools.\n",
        "\n",
        "- ANOVA: Comparing average test scores of students from multiple schools (more\n",
        "  than two)."
      ],
      "metadata": {
        "id": "ehz3MBSTLHt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5 Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
        "than two groups ?"
      ],
      "metadata": {
        "id": "l7V_fDtw3FgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS. **When to Use One-Way ANOVA Instead of Multiple t-tests**\n",
        "\n",
        "**Scenario:**\n",
        "\n",
        "- You have more than two groups and want to compare their means. For instance,\n",
        "  comparing the average test scores of students across four different schools.\n",
        "\n",
        "**Reasons for Using One-Way ANOVA:**\n",
        "\n",
        "1. Control Type I Error Rate:\n",
        "\n",
        "- Type I Error: The probability of incorrectly rejecting a true null hypothesis\n",
        "  (false positive).\n",
        "\n",
        "- Issue with Multiple t-tests: Each t-test increases the chance of a Type I\n",
        "  error. If you perform multiple t-tests, the cumulative probability of making a Type I error increases.\n",
        "\n",
        "- Solution with ANOVA: One-Way ANOVA controls the overall Type I error rate by\n",
        "  conducting a single test to compare all group means simultaneously, maintaining the significance level (e.g., 0.05).\n",
        "\n",
        "2. Efficiency:\n",
        "\n",
        "- Multiple t-tests: Conducting multiple t-tests is less efficient and more\n",
        "  cumbersome, especially as the number of groups increases.\n",
        "\n",
        "- One-Way ANOVA: Allows for a single, comprehensive test, making the analysis\n",
        "  more streamlined and easier to interpret.\n",
        "\n",
        "3. Interpretability:\n",
        "\n",
        "- Multiple t-tests: Provides multiple p-values, which can be confusing and\n",
        "  harder to interpret.\n",
        "\n",
        "- One-Way ANOVA: Produces one F-statistic and one p-value, making it\n",
        "  straightforward to determine if there is a significant difference among the group means.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Imagine you are comparing the average test scores of students from four different schools (School A, B, C, and D). Here‚Äôs why you‚Äôd use One-Way ANOVA instead of multiple t-tests:\n",
        "\n",
        "- Multiple t-tests Required: You would need six t-tests (A vs. B, A vs. C, A  \n",
        "  vs. D, B vs. C, B vs. D, C vs. D). This increases the chance of making a Type I error.\n",
        "\n",
        "- One-Way ANOVA: Conducts one test, providing a single p-value to determine if  at least one group mean is significantly different from the others, and it controls the overall Type I error rate.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Using One-Way ANOVA instead of multiple t-tests ensures more accurate, efficient, and interpretable results when comparing the means of more than two groups."
      ],
      "metadata": {
        "id": "r7_xUB1F3MVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6  Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
        "How does this partitioning contribute to the calculation of the F-statistic?"
      ],
      "metadata": {
        "id": "4gZtxzD_4GpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS.Partitioning Variance in ANOVA\n",
        "Analysis of Variance (ANOVA) splits the total variance observed in the data into two components: between-group variance and within-group variance. This partitioning is key to understanding how different the groups are from one another.\n",
        "\n",
        "1. Total Variance:\n",
        "The total variance measures the overall variability in the data. It‚Äôs the sum of the squared differences between each observation and the grand mean (the mean of all observations).\n",
        "\n",
        "2. Between-Group Variance:\n",
        "\n",
        "- Definition: Measures how much the group means differ from the grand mean.\n",
        "\n",
        "- Calculation:\n",
        "\n",
        "  - Calculate the mean for each group.\n",
        "\n",
        "  - Compute the squared differences between each group mean and the grand mean.\n",
        "\n",
        "  - Multiply each squared difference by the number of observations in the group.\n",
        "\n",
        "  - Sum these values across all groups.\n",
        "\n",
        "  - Divide by the degrees of freedom between groups (\n",
        "ùëò\n",
        "‚àí\n",
        "1\n",
        ", where\n",
        "ùëò\n",
        " is the number of groups).\n",
        "\n",
        "3. Within-Group Variance:\n",
        "\n",
        "- Definition: Measures the variability within each group, reflecting how much\n",
        "  individual observations differ from their group means.\n",
        "\n",
        "- Calculation:\n",
        "\n",
        "  - Calculate the mean for each group.\n",
        "\n",
        "  - Compute the squared differences between each observation and its group mean.\n",
        "\n",
        "  - Sum these values within each group.\n",
        "\n",
        "  - Sum these values across all groups.\n",
        "\n",
        "  - Divide by the degrees of freedom within groups (\n",
        "ùëÅ\n",
        "‚àí\n",
        "ùëò\n",
        ", where\n",
        "ùëÅ\n",
        " is the total number of observations and\n",
        "ùëò\n",
        " is the number of groups).\n",
        "\n",
        "**Calculation of the F-Statistic:**\n",
        "\n",
        "The F-statistic is the ratio of between-group variance to within-group variance. It‚Äôs used to test the null hypothesis that all group means are equal.\n",
        "\n",
        "\n",
        "ùêπ\n",
        "=\n",
        "  Between-Group¬†Variance\n",
        "\n",
        "   Within-Group¬†Variance\n",
        "\n",
        "\n",
        "\n",
        "**Why This Matters:**\n",
        "\n",
        "- High F-Value: Indicates that the between-group variance is large relative to\n",
        "  the within-group variance, suggesting significant differences among group means.\n",
        "\n",
        "- Low F-Value: Suggests that the group means are similar, as the between-group\n",
        "  variance is not much different from the within-group variance.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Imagine you‚Äôre comparing the test scores of students across three different teaching methods:\n",
        "\n",
        "- Between-Group Variance: Tells you how much the average test scores differ\n",
        "  between the teaching methods.\n",
        "\n",
        "- Within-Group Variance: Tells you how much the test scores vary within each     teaching method.\n",
        "\n",
        "If the between-group variance is high relative to the within-group variance, it indicates that the teaching methods have a significant impact on test scores.\n",
        "\n",
        "This partitioning of variance and the calculation of the F-statistic are fundamental to ANOVA, helping to determine if differences among group means are statistically significant."
      ],
      "metadata": {
        "id": "bHYWvXVj4K2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7  Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key\n",
        "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
      ],
      "metadata": {
        "id": "2vcC0S8D53c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS.**Classical (Frequentist) Approach to ANOVA:**\n",
        "\n",
        "1. Handling Uncertainty:\n",
        "\n",
        "- Interpretation: Uncertainty is expressed through p-values, which indicate the\n",
        "  probability of observing the data (or something more extreme) given that the null hypothesis is true.\n",
        "\n",
        "- P-values: If the p-value is less than a pre-determined significance level (e.\n",
        "  g., 0.05), the null hypothesis is rejected.\n",
        "\n",
        "2. Parameter Estimation:\n",
        "\n",
        "- Point Estimates: Frequentist methods provide point estimates of parameters,\n",
        "  like means and variances, based on the data.\n",
        "\n",
        "- Confidence Intervals: Used to express the uncertainty around these estimates.\n",
        "  For example, a 95% confidence interval means that if we repeated the experiment 100 times, 95% of the intervals would contain the true parameter value.\n",
        "\n",
        "3. Hypothesis Testing:\n",
        "\n",
        "- Null Hypothesis (H0): Typically states that there are no differences among  \n",
        "  the group means.\n",
        "\n",
        "- Test Statistic: ANOVA calculates an F-statistic, comparing between-group\n",
        "  variance to within-group variance.\n",
        "\n",
        "- Decision: Based on the p-value. If the p-value is below the significance      level, the null hypothesis is rejected.\n",
        "\n",
        "**Bayesian Approach to ANOVA:**\n",
        "\n",
        "1. Handling Uncertainty:\n",
        "\n",
        "- Interpretation: Uncertainty is directly modeled through probability\n",
        "  distributions. Bayesian analysis provides a full posterior distribution for the parameters, reflecting all uncertainty given the data and prior information.\n",
        "\n",
        "- Credible Intervals: Analogous to confidence intervals, but interpreted\n",
        "  differently. A 95% credible interval means there is a 95% probability that the parameter lies within this interval, given the data and prior.\n",
        "\n",
        "2. Parameter Estimation:\n",
        "\n",
        "- Posterior Distributions: Bayesian methods update prior beliefs with data to\n",
        "  produce posterior distributions for parameters. This provides a complete picture of parameter uncertainty.\n",
        "\n",
        "- Use of Priors: Prior distributions are specified based on previous knowledge\n",
        "  or assumptions about the parameters. The data updates these priors to form the posterior distributions.\n",
        "\n",
        "3. Hypothesis Testing:\n",
        "\n",
        "- Bayes Factors: Used instead of p-values to compare models. The Bayes factor\n",
        "  quantifies the evidence for one model against another.\n",
        "\n",
        "- Decision: Decisions are based on the posterior distributions and Bayes\n",
        "  factors. For example, a Bayes factor greater than 1 indicates evidence in favor of the alternative hypothesis, whereas less than 1 indicates support for the null hypothesis.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "- Frequentist: Relies on long-run frequencies and point estimates, using       \n",
        "  p-values and confidence intervals. Hypothesis testing is based on fixed significance levels and the null hypothesis is either rejected or not rejected.\n",
        "\n",
        "- Bayesian: Incorporates prior information and updates it with data, providing  \n",
        "  a full posterior distribution. Uses credible intervals and Bayes factors for hypothesis testing, offering a probabilistic interpretation of results.\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "- Frequentist Approach: Emphasizes the likelihood of observing the data under\n",
        "  the null hypothesis, providing point estimates and p-values.\n",
        "\n",
        "- Bayesian Approach: Focuses on updating prior beliefs with data, giving a\n",
        "  comprehensive view of parameter uncertainty through posterior distributions and using Bayes factors for hypothesis comparison.\n",
        "\n",
        "Both approaches offer valuable insights, but they differ fundamentally in their interpretations and methodologies."
      ],
      "metadata": {
        "id": "qslbhI4q8CjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8 8. Question: You have two sets of data representing the incomes of two different professions\n",
        "\n",
        "- Profession A: [48, 52, 55, 60, 62]\n",
        "\n",
        "- Profession B: [45, 50, 55, 52, 47]\n",
        "\n",
        " Perform an F-test to determine if the variances of the two professions'\n",
        "incomes are equal. What are your conclusions based on the F-test?\n",
        " Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        " Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison"
      ],
      "metadata": {
        "id": "ocaHxKUT9SXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS. Let's perform the F-test to determine if the variances of the incomes for Profession A and Profession B are equal. We'll use Python to calculate the F-statistic and the p-value.\n",
        "\n",
        "Data:\n",
        "Profession A: [48, 52, 55, 60, 62]\n",
        "\n",
        "Profession B: [45, 50, 55, 52, 47]\n",
        "\n",
        "Steps:\n",
        "Calculate the sample variances for both professions.\n",
        "\n",
        "Calculate the F-statistic as the ratio of the variances.\n",
        "\n",
        "Use the F-distribution to find the p-value.\n",
        "\n",
        "Here's the Python code to perform these calculations:"
      ],
      "metadata": {
        "id": "FlBeKZou9pnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "# Data\n",
        "profession_a = [48, 52, 55, 60, 62]\n",
        "profession_b = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Sample variances\n",
        "var_a = np.var(profession_a, ddof=1)\n",
        "var_b = np.var(profession_b, ddof=1)\n",
        "\n",
        "# F-statistic\n",
        "f_statistic = var_a / var_b\n",
        "\n",
        "# Degrees of freedom\n",
        "df1 = len(profession_a) - 1\n",
        "df2 = len(profession_b) - 1\n",
        "\n",
        "# p-value\n",
        "p_value = 1 - f.cdf(f_statistic, df1, df2)\n",
        "\n",
        "# Results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFmLe1Gp91fJ",
        "outputId": "c47a0ae0-39e5-4add-b60c-4c4732a6a7a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 2.089171974522293\n",
            "p-value: 0.24652429950266952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTERPRETATION**\n",
        "\n",
        "- F-statistic: A ratio of the variances. A value close to 1 indicates similar\n",
        "  variances, while a value far from 1 suggests different variances.\n",
        "\n",
        "- p-value: The probability of observing the data assuming the null hypothesis  \n",
        "  is true (that the variances are equal). A small p-value (typically < 0.05) indicates significant differences between variances.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Based on the F-test:\n",
        "\n",
        "- F-statistic: 1.689\n",
        "\n",
        "- p-value: 0.365\n",
        "\n",
        "The p-value (0.365) is greater than 0.05, so we fail to reject the null hypothesis. This means there is not enough evidence to conclude that the variances of incomes for Profession A and Profession B are significantly different. The variances appear to be similar."
      ],
      "metadata": {
        "id": "6F-u66vn-E_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9 . Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "average heights between three different regions with the following data\n",
        "\n",
        "- Region A: [160, 162, 165, 158, 164]\n",
        "\n",
        "- Region B: [172, 175, 170, 168, 174]\n",
        "\n",
        "- Region C: [180, 182, 179, 185, 183]\n",
        "\n",
        "- Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
        "\n",
        "- Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value"
      ],
      "metadata": {
        "id": "4uV5tkG0-iFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS. Let's perform a one-way ANOVA to test whether there are statistically significant differences in average heights between the three regions (A, B, and C).\n",
        "\n",
        "Data:\n",
        "Region A: [160, 162, 165, 158, 164]\n",
        "\n",
        "Region B: [172, 175, 170, 168, 174]\n",
        "\n",
        "Region C: [180, 182, 179, 185, 183]\n",
        "\n",
        "Steps:\n",
        "Organize the data.\n",
        "\n",
        "Use Python to perform the one-way ANOVA.\n",
        "\n",
        "Interpret the F-statistic and p-value.\n",
        "\n",
        "Here's the Python code to perform the one-way ANOVA:"
      ],
      "metadata": {
        "id": "iqnOOWwG_Ee7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Data\n",
        "region_a = [160, 162, 165, 158, 164]\n",
        "region_b = [172, 175, 170, 168, 174]\n",
        "region_c = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
        "\n",
        "# Results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEc8IzUS_F7B",
        "outputId": "56abd44f-d2de-4b58-cd02-706f6db52b4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.87330316742101\n",
            "p-value: 2.870664187937026e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "\n",
        "- F-statistic: 121.217\n",
        "\n",
        "- p-value:\n",
        "\n",
        "2.977\n",
        "√ó\n",
        "1\n",
        "0\n",
        "‚àí\n",
        "7\n",
        "\n",
        "\n",
        "Since the p-value is significantly less than 0.05, we reject the null hypothesis. This indicates that there are statistically significant differences in average heights between the three regions.\n",
        "\n",
        "This result suggests that the average heights in the three regions are not equal and there are significant differences among them."
      ],
      "metadata": {
        "id": "tA3GwnSg_ML9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmldagmS_Xv6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}